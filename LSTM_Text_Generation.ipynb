{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vIpnnpXp-L3",
        "outputId": "bda6760f-4169-421a-b20b-db987be7671d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1076/1076 [==============================] - 481s 442ms/step - loss: 7.0008\n",
            "Epoch 2/100\n",
            "1076/1076 [==============================] - 481s 447ms/step - loss: 5.7145\n",
            "Epoch 3/100\n",
            "1076/1076 [==============================] - 473s 439ms/step - loss: 5.0728\n",
            "Epoch 4/100\n",
            "1076/1076 [==============================] - 471s 438ms/step - loss: 4.7107\n",
            "Epoch 5/100\n",
            "1076/1076 [==============================] - 476s 442ms/step - loss: 4.3959\n",
            "Epoch 6/100\n",
            "1076/1076 [==============================] - 472s 439ms/step - loss: 4.1074\n",
            "Epoch 7/100\n",
            "1076/1076 [==============================] - 474s 441ms/step - loss: 3.8387\n",
            "Epoch 8/100\n",
            "1076/1076 [==============================] - 474s 440ms/step - loss: 3.5852\n",
            "Epoch 9/100\n",
            "1076/1076 [==============================] - 463s 430ms/step - loss: 3.3411\n",
            "Epoch 10/100\n",
            "1076/1076 [==============================] - 461s 429ms/step - loss: 3.1077\n",
            "Epoch 11/100\n",
            "1076/1076 [==============================] - 459s 427ms/step - loss: 2.8884\n",
            "Epoch 12/100\n",
            "1076/1076 [==============================] - 462s 430ms/step - loss: 2.6787\n",
            "Epoch 13/100\n",
            "1076/1076 [==============================] - 466s 433ms/step - loss: 2.4839\n",
            "Epoch 14/100\n",
            "1076/1076 [==============================] - 461s 428ms/step - loss: 2.3054\n",
            "Epoch 15/100\n",
            "1076/1076 [==============================] - 470s 437ms/step - loss: 2.1427\n",
            "Epoch 16/100\n",
            " 307/1076 [=======>......................] - ETA: 5:38 - loss: 1.9281"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding\n",
        "\n",
        "# ----------------------\n",
        "# 1. Load and Prepare Text\n",
        "# ----------------------\n",
        "with open('/content/ArticlesApril2017.csv', 'r') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "sequences = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "sequence_length = 100\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(sequence_length, len(sequences)):\n",
        "    X.append(sequences[i - sequence_length:i])\n",
        "    y.append(sequences[i])\n",
        "X = np.array(X)\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# ----------------------\n",
        "# 2. Define the LSTM Model\n",
        "# ----------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=sequence_length))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# ----------------------\n",
        "# 3. Train the Model\n",
        "# ----------------------\n",
        "model.fit(X, y, batch_size=64, epochs=100)\n",
        "\n",
        "# ----------------------\n",
        "# 4. Text Generation\n",
        "# ----------------------\n",
        "seed_text = \"Start with some words\"\n",
        "next_words = 50\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    padded = pad_sequences([token_list], maxlen=sequence_length - 1, padding='pre')\n",
        "    predicted = model.predict_classes(padded, verbose=0)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "print(seed_text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}